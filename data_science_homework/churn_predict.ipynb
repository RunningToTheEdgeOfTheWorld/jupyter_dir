{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_train_test_data():\n",
    "    import sqlite3\n",
    "    conn = sqlite3.connect('tweets.db')\n",
    "    sql = \"\"\"\n",
    "        select tweets.tid, date, text, churn, \"set\" from tweets join churn on churn.tid = tweets.tid\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    tw_data = pd.DataFrame(cursor.fetchall())\n",
    "    cursor.close()\n",
    "    tw_data.columns = ['tid', 'date', 'text', 'churn', 'set']\n",
    "    tw_data.tid = tw_data.tid.astype(np.int)\n",
    "    tw_data.date = pd.to_datetime(tw_data.date)\n",
    "    tw_data.pop('date')\n",
    "    \n",
    "    tw_train = tw_data[tw_data.set == 'training']\n",
    "    tw_test = tw_data[tw_data.set == 'hidden']\n",
    "    tw_train.pop('set')\n",
    "    tw_test.pop('set')\n",
    "\n",
    "    return tw_train, tw_test\n",
    "tw_train_valid, tw_test = get_train_test_data()\n",
    "\n",
    "tw_test_x = tw_test['text']\n",
    "tw_test_y = tw_test['churn']\n",
    "\n",
    "tw_train_valid_x = tw_train_valid['text']\n",
    "tw_train_valid_y = tw_train_valid['churn']\n",
    "\n",
    "tw_train_x, tw_valid_x, tw_train_y, tw_valid_y = train_test_split(tw_train_valid_x, tw_train_valid_y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################choice related words##############################\n",
      "['im', 'leaving', 'contract', 'tmobile', 'leave', 'wait', 'companies', 'goodbye', 'cancel', 'thinking', 'cant', 'till', 'hello', 'bye', 'my', 'done', 'to', 'months', 'expensive', 'lines', 'fee', 'switching', 'reason', 'canceling', 'december', 'mom', 'next', 'hurry', 'net10', 'weeks', 'insane', 'anyway', 'fuck', 'more', 'switch', 'prices', 'asses', 'bullshit', 'considering', 'soon', 'swear', 'yea', 'hate', 'metro', 'finna', 'verizonwireless', 'they', 'maybe', 'gigs', 'wit', 'frustrated', 'guy', 'havent', 'users', 'call', 'verse', 'home', 'sfgiants', 'update', '450', 'fios', 'lumia', 'into', 'white', 'calls', 'like', 'never', 'it', 'commercials', 'probably', 'customers', 'before', 'store', 'down', 'on', 'called', 'work', 'note', 'and', 'didnt', 'text', 'see', 'tired', 'lte', 'he', 'disappointed', 'end', 'us', 'in', 'co', 'give', 'said', 'every', 'mobile', 'game', 'had', 'your', 'park', 'center', 'the']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import collections\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "MOST_RELATE_WORD_COUNT = 100\n",
    "\n",
    "def get_relate_cv():\n",
    "    pat = re.compile('[@,;.*/!?#]')\n",
    "    replac_sym = re.compile(pat)\n",
    "\n",
    "    freq_cv = TfidfVectorizer()\n",
    "    sum_text = tw_train_x.map(lambda i: re.sub(pat, ' ', i)).sum().lower()\n",
    "    ct = collections.Counter(sum_text.split())\n",
    "    for k in ct.copy():\n",
    "        if ct[k] <= 2:\n",
    "            ct.pop(k)\n",
    "    freq_cv.fit(list(ct.keys()))\n",
    "    \n",
    "    cv = TfidfVectorizer()\n",
    "    train_feature = pd.DataFrame(freq_cv.transform(tw_train_x).toarray(), index=tw_train_x.index)\n",
    "    train_feature.columns = freq_cv.get_feature_names()\n",
    "    word_corr = (train_feature.corrwith(tw_train_y) - train_feature.corrwith(-tw_train_y+1)).dropna()\n",
    "    relate_words = list(word_corr.sort_values(ascending=False).index)\n",
    "    _bench = int(MOST_RELATE_WORD_COUNT/2)\n",
    "    choice_words = relate_words[:_bench] + relate_words[-_bench:]\n",
    "    cv.fit(choice_words)\n",
    "    \n",
    "    print('choice related words'.center(80, '#'))\n",
    "    print(choice_words)\n",
    "#     print(word_corr.sort_values(ascending=False))\n",
    "    return cv\n",
    "\n",
    "cv = get_relate_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8202247191011236\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.92      0.89       491\n",
      "        1.0       0.60      0.45      0.52       132\n",
      "\n",
      "avg / total       0.81      0.82      0.81       623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_fea = pd.DataFrame(cv.transform(tw_train_x).toarray(), columns=cv.get_feature_names())\n",
    "clf.fit(train_fea, tw_train_y).fit(train_fea, tw_train_y).fit(train_fea, tw_train_y)\n",
    "\n",
    "valid_fea = pd.DataFrame(cv.transform(tw_valid_x).toarray(), columns=cv.get_feature_names())\n",
    "print(clf.score(valid_fea, tw_valid_y))\n",
    "print(classification_report(tw_valid_y, clf.predict(valid_fea)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "test_fea = pd.DataFrame(cv.transform(tw_test_x).toarray(), columns=cv.get_feature_names())\n",
    "predict_test = pd.DataFrame(clf.predict(test_fea).astype(np.int), index=tw_test.tid, columns=['Churn'])\n",
    "predict_test.to_csv('ID_666_Q_2_4_1.csv')\n",
    "\n",
    "with open('ID_666_Q_2_4_1.pickle', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2492"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tw_train_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
